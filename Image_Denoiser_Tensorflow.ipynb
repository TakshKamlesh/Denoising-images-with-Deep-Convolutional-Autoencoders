{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Denoiser Tensorflow",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "hpPnhe-ZHVLp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L3i_7RSxHtRk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "  \n",
        "  (X_train, _), (X_test, _) = tf.keras.datasets.mnist.load_data()\n",
        "  \n",
        "  X_train = X_train.astype('float32') / 255. \n",
        "  \n",
        "  X_test = X_test.astype('float32') / 255.\n",
        "  \n",
        "  X_train = tf.reshape(X_train, (len(X_train), 28, 28, 1))\n",
        "  \n",
        "  X_test = tf.reshape(X_test, (len(X_test), 28, 28, 1)) \n",
        "  \n",
        "  noise_factor = 0.5\n",
        "  \n",
        "  x_train_noisy = X_train + noise_factor * tf.random.normal(mean=0.0, stddev=1.0, shape=X_train.shape)\n",
        "  \n",
        "  x_test_noisy = X_test + noise_factor * tf.random.normal(mean=0.0, stddev=1.0, shape=X_test.shape)\n",
        "  \n",
        "  x_train_noisy = tf.clip_by_value(x_train_noisy, 0., 1.)\n",
        "  \n",
        "  x_test_noisy = tf.clip_by_value(x_test_noisy, 0., 1.)\n",
        "  \n",
        "  return X_train, X_test, x_train_noisy, x_test_noisy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "byoeBcd6NLWy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_model() :\n",
        "  \n",
        "  input_image = tf.keras.layers.Input(shape=(28,28,1))\n",
        "  \n",
        "  x = tf.layers.Conv2D(16, \n",
        "                       kernel_size = (3, 3), \n",
        "                       activation ='relu', \n",
        "                       padding = 'same')(input_image)\n",
        "  \n",
        "  x = tf.layers.MaxPooling2D(pool_size = (2, 2), \n",
        "                             strides = 1, \n",
        "                             padding='same')(x)\n",
        "  \n",
        "  x = tf.layers.Conv2D(8, \n",
        "                       kernel_size = (3, 3), \n",
        "                       activation='relu', \n",
        "                       padding='same')(x)\n",
        "  \n",
        "  x = tf.layers.MaxPooling2D(pool_size = (2, 2), \n",
        "                             strides = 1, \n",
        "                             padding='same')(x)\n",
        "  \n",
        "  x = tf.layers.Conv2D(8, \n",
        "                       kernel_size = (3, 3), \n",
        "                       activation='relu', \n",
        "                       padding='same')(x)\n",
        "  \n",
        "  encoded = tf.layers.MaxPooling2D(pool_size = (2, 2), \n",
        "                                   strides = 1,  \n",
        "                                   padding='same', \n",
        "                                   name='encoder')(x)\n",
        "  \n",
        "  x = tf.layers.Conv2D(8, \n",
        "                       kernel_size = (3, 3), \n",
        "                       activation='relu', \n",
        "                       padding='same')(encoded)\n",
        "  \n",
        "  x = tf.keras.layers.UpSampling2D(size = (2, 2))(x)\n",
        "  \n",
        "  x = tf.layers.Conv2D(8, \n",
        "                       kernel_size = (3, 3),\n",
        "                       activation='relu', \n",
        "                       padding='same')(x)\n",
        "  \n",
        "  x = tf.keras.layers.UpSampling2D(size = (2, 2))(x)\n",
        "  \n",
        "  x = tf.layers.Conv2D(16, \n",
        "                       kernel_size = (3, 3),\n",
        "                       activation='relu')(x)\n",
        "  \n",
        "  x = tf.keras.layers.UpSampling2D(size = (2, 2))(x)\n",
        "  \n",
        "  decoded = tf.layers.Conv2D(1, \n",
        "                             kernel_size = (3, 3), \n",
        "                             activation='sigmoid', \n",
        "                             padding='same')(x)\n",
        "  \n",
        "  autoencoder = tf.keras.models.Model(input_image, decoded)\n",
        "  \n",
        "  return autoencoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CK_1MiQBRC9p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "b01863cb-f6f3-4be6-a719-827344a5f214"
      },
      "cell_type": "code",
      "source": [
        "image_denoiser = build_model()\n",
        "  \n",
        "x_train, x_test, x_train_noisy, x_test_noisy = load_data()\n",
        "  \n",
        "image_denoiser.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "  \n",
        "image_denoiser.fit(x_train_noisy, x_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=128,\n",
        "                    shuffle=True,\n",
        "                    validation_data=(x_test_noisy, x_test),\n",
        "                    )\n",
        "  \n",
        " "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a4ff767e0bbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_noisy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                     )\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle)\u001b[0m\n\u001b[1;32m   2202\u001b[0m     \u001b[0;31m# Validates `steps` argument based on x's type.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheck_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2204\u001b[0;31m       \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_steps_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2206\u001b[0m     \u001b[0mis_x_eager_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_steps_argument\u001b[0;34m(input_data, steps, steps_name)\u001b[0m\n\u001b[1;32m    958\u001b[0m       raise ValueError('When using {input_type} as input to a model, you should'\n\u001b[1;32m    959\u001b[0m                        ' specify the `{steps_name}` argument.'.format(\n\u001b[0;32m--> 960\u001b[0;31m                            input_type=input_type_str, steps_name=steps_name))\n\u001b[0m\u001b[1;32m    961\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: When using data tensors as input to a model, you should specify the `steps_per_epoch` argument."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "W2r5jQUdRGDx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "3306677d-55a9-48a5-9081-7f30495d6209"
      },
      "cell_type": "code",
      "source": [
        "train_model() "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c3162e7c9a7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-f8dcee7a1a62>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_noisy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle)\u001b[0m\n\u001b[1;32m   2202\u001b[0m     \u001b[0;31m# Validates `steps` argument based on x's type.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheck_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2204\u001b[0;31m       \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_steps_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2206\u001b[0m     \u001b[0mis_x_eager_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_steps_argument\u001b[0;34m(input_data, steps, steps_name)\u001b[0m\n\u001b[1;32m    958\u001b[0m       raise ValueError('When using {input_type} as input to a model, you should'\n\u001b[1;32m    959\u001b[0m                        ' specify the `{steps_name}` argument.'.format(\n\u001b[0;32m--> 960\u001b[0;31m                            input_type=input_type_str, steps_name=steps_name))\n\u001b[0m\u001b[1;32m    961\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: When using data tensors as input to a model, you should specify the `steps_per_epoch` argument."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "CXJjdID_ssmv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}